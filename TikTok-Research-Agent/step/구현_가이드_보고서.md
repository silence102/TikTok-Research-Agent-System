# TikTok Research Agent - 구현 가이드 보고서

## 문서 정보
- **작성일**: 2025-12-19
- **목적**: 사전 준비 완료 후 실제 구현을 위한 순차적 작업 가이드
- **대상**: Agent 1, 2, 3 순차 구현

---

## 현재 상태 (Phase 0 완료)

### 완료된 사전 준비
✅ Python 3.12.7 venv 생성 및 패키지 설치
✅ Airtable Base 생성 및 테이블 2개 구성 (필드 상세 스키마는 `docs/AIRTABLE_SCHEMA.md` 참조)
✅ API 키 전체 발급 및 .env 설정 완료 (모든 credential은 `.env` 파일에서 확인)
✅ n8n Docker 컨테이너 실행 중 (http://localhost:5678)
✅ Airtable 연결 테스트 완료 (scripts/test_airtable.py)
✅ 문서화 완료 (PRD, TechStack, Tasks, AIRTABLE_SCHEMA, 준비 보고서)

---

## 구현 순서 및 계획

### Agent 1: TikTok Trend Collector (Day 1-2, 예상 6-8시간)
**목표**: Apify로 TikTok 해시태그 데이터 수집 → OpenAI 분류 → Airtable 저장

### Agent 2: RSS News Collector (Day 3-4, 예상 6-8시간)
**목표**: RSS 피드 5개 수집 → OpenAI 요약 → Airtable 저장

### Agent 3: CLI Q&A Interface (Day 5-7, 예상 8-12시간)
**목표**: Airtable 데이터 조회 → OpenAI RAG 답변 → CLI 출력

---

## 🎯 Task 1: Agent 1 - TikTok Trend Collector

### 1.1 n8n 초기 설정 (30분)

#### 작업 내용
1. n8n 웹 인터페이스 접속
   - URL: http://localhost:5678
   - 초기 계정 생성 (이메일/비밀번호)

2. Credentials 등록 (3개)

   > **중요**: 모든 API 키는 `.env` 파일에서 확인하세요.

   **Credential 1: Airtable**
   - Name: `Airtable - TikTok Research`
   - Type: Airtable Personal Access Token API
   - Access Token: `.env` 파일의 `AIRTABLE_PAT` 값 입력

   **Credential 2: OpenAI**
   - Name: `OpenAI - TikTok Research`
   - Type: OpenAI API
   - API Key: `.env` 파일의 `OPENAI_API_KEY` 값 입력

   **Credential 3: Apify**
   - Name: `Apify - TikTok Scraper`
   - Type: HTTP Header Auth
   - Name: `Authorization`
   - Value: `Bearer ` + `.env` 파일의 `APIFY_API_TOKEN` 값

3. 라이선스 키 등록
   - Settings → License
   - License Key: `.env` 파일의 `N8N_LICENSE_KEY` 값 입력

### 1.2 Apify API 구조 파악 (1시간)

#### 작업 내용
1. Apify TikTok Hashtag Scraper 문서 확인
   - Actor: `clockworks/tiktok-hashtag-scraper`
   - URL: https://apify.com/clockworks/tiktok-hashtag-scraper

2. API 호출 구조 테스트 (Postman 또는 curl)
   ```bash
   # 1단계: Run 시작 (API 토큰은 .env 파일에서 확인)
   curl -X POST "https://api.apify.com/v2/acts/clockworks~tiktok-hashtag-scraper/runs" \
     -H "Authorization: Bearer ${APIFY_API_TOKEN}" \
     -H "Content-Type: application/json" \
     -d '{
       "hashtags": ["buldak"],
       "resultsPerPage": 20,
       "shouldDownloadVideos": false
     }'

   # 응답에서 defaultDatasetId 확인

   # 2단계: 결과 조회 (2-3분 후)
   curl "https://api.apify.com/v2/datasets/{datasetId}/items"
   ```

   > **참고**: `${APIFY_API_TOKEN}`은 `.env` 파일의 `APIFY_API_TOKEN` 값으로 대체

3. 응답 데이터 구조 분석
   - 필요한 필드: `videoMeta.diggCount`, `text`, `musicMeta.musicName`, `webVideoUrl`
   - trend_score 계산 공식 설계

### 1.3 n8n 워크플로우 설계 문서 작성 (1시간)

#### 파일 생성: `docs/workflows/agent1_design.md`

```markdown
# Agent 1 워크플로우 설계

## 노드 구조 (10개 노드)

1. Schedule Trigger
   - Cron: `0 9 * * *` (매일 09:00 KST)

2. Set Node - 해시태그 리스트
   - 배열: ["buldak", "spicychallenge", "mukbang", "koreanfood", "foodchallenge"]

3. Loop Over Items

4. HTTP Request - Apify Run 시작
   - POST: `https://api.apify.com/v2/acts/clockworks~tiktok-hashtag-scraper/runs`

5. Wait - 2분

6. HTTP Request - 결과 조회
   - GET: `https://api.apify.com/v2/datasets/{{datasetId}}/items`

7. Function - 데이터 정제 및 trend_score 계산

8. OpenAI - 카테고리 분류

9. Function - Airtable 포맷 변환

10. Airtable - Create Record

## trend_score 계산 공식
```javascript
trend_score = Math.min(100,
  (video_count / 1000) * 40 +  // 영상 수 가중치
  (growth_rate || 0) * 30 +     // 성장률 가중치
  (engagement_rate * 100) * 30  // 참여율 가중치
)
```

## OpenAI 프롬프트
```
You are a TikTok content categorizer.

Categorize the following keyword into ONE category:
- Food
- Dance
- Comedy
- Review
- Beauty
- Other

Keyword: {{keyword}}
Sample videos: {{sample_texts}}

Respond ONLY with the category name.
```
```

### 1.4 n8n 워크플로우 구현 (3-4시간)

#### 작업 순서

**Step 1: 새 워크플로우 생성**
- Workflows → New Workflow
- Name: `Agent 1 - TikTok Trend Collector`

**Step 2: 노드 추가 (순서대로)**

1. **Schedule Trigger 노드**
   - Add Node → Schedule Trigger
   - Trigger Interval: Cron
   - Cron Expression: `0 9 * * *`
   - Timezone: `Asia/Seoul`

2. **Set 노드 (해시태그 리스트)**
   - Add Node → Set
   - Keep Only Set: True
   - Values to Set:
     - Name: `hashtags`
     - Value: `["buldak", "spicychallenge", "mukbang", "koreanfood", "foodchallenge"]` (JSON)

3. **Split In Batches 노드**
   - Add Node → Split In Batches
   - Batch Size: 1
   - Options → Reset: False

4. **HTTP Request 노드 (Apify Run)**
   - Add Node → HTTP Request
   - Method: POST
   - URL: `https://api.apify.com/v2/acts/clockworks~tiktok-hashtag-scraper/runs`
   - Authentication: Predefined Credential Type → Apify
   - Send Body: True
   - Body Content Type: JSON
   - Specify Body: Using JSON
   - JSON Body:
     ```json
     {
       "hashtags": ["{{ $json.hashtags[0] }}"],
       "resultsPerPage": 50,
       "shouldDownloadVideos": false
     }
     ```

5. **Wait 노드**
   - Add Node → Wait
   - Resume: After Time Interval
   - Wait Amount: 2
   - Wait Unit: Minutes

6. **HTTP Request 노드 (결과 조회)**
   - Method: GET
   - URL: `https://api.apify.com/v2/datasets/{{ $json.defaultDatasetId }}/items`
   - Authentication: Apify

7. **Function 노드 (데이터 정제)**
   - Add Node → Code → Run Once for All Items
   - JavaScript 코드:
     ```javascript
     const items = $input.all();
     const hashtag = items[0].json.hashtags[0];
     const videos = items[0].json.body || [];

     if (videos.length === 0) {
       return [{ json: { error: 'No videos found' } }];
     }

     // 집계
     const video_count = videos.length;
     const total_views = videos.reduce((sum, v) => sum + (v.playCount || 0), 0);
     const total_likes = videos.reduce((sum, v) => sum + (v.diggCount || 0), 0);
     const engagement_rate = total_views > 0 ? total_likes / total_views : 0;

     // trend_score 계산
     const trend_score = Math.min(100, Math.round(
       (video_count / 1000) * 40 +
       (engagement_rate * 100) * 60
     ));

     // 샘플 텍스트 (카테고리 분류용)
     const sample_texts = videos.slice(0, 3).map(v => v.text || '').join(' | ');

     // 대표 영상 URL
     const sample_video_url = videos[0]?.webVideoUrl || '';

     return [{
       json: {
         keyword: hashtag,
         video_count: video_count,
         trend_score: trend_score,
         growth_rate: null,
         sample_video_url: sample_video_url,
         sample_texts: sample_texts,
         collected_at: new Date().toISOString().split('T')[0],
         source: 'Apify'
       }
     }];
     ```

8. **OpenAI 노드 (카테고리 분류)**
   - Add Node → OpenAI
   - Resource: Chat
   - Model: gpt-4o-mini
   - Prompt Type: Define Below
   - Message Type: User Message
   - Text:
     ```
     Categorize this TikTok keyword into ONE category: Food, Dance, Comedy, Review, Beauty, Other

     Keyword: {{ $json.keyword }}
     Sample content: {{ $json.sample_texts }}

     Respond with ONLY the category name.
     ```
   - Options → Temperature: 0.3

9. **Set 노드 (최종 데이터 준비)**
   - Merge with previous data
   - Values to Set:
     - Name: `category`
     - Value: `{{ $json.message.content }}`
     - Name: `description`
     - Value: `Trend score: {{ $('Function').item.json.trend_score }}`

10. **Airtable 노드 (Create)**
    - Add Node → Airtable
    - Credential: Airtable - TikTok Research
    - Operation: Create
    - Base: `.env` 파일의 `AIRTABLE_BASE_ID` 값 (또는 직접 Base 선택)
    - Table: `tiktok_trends`
    - Fields:
      - keyword: `{{ $('Function').item.json.keyword }}`
      - trend_score: `{{ $('Function').item.json.trend_score }}`
      - video_count: `{{ $('Function').item.json.video_count }}`
      - category: `{{ $json.category }}`
      - sample_video_url: `{{ $('Function').item.json.sample_video_url }}`
      - collected_at: `{{ $('Function').item.json.collected_at }}`
      - source: `{{ $('Function').item.json.source }}`

**Step 3: 노드 연결**
- 각 노드를 순서대로 연결
- Save Workflow

### 1.5 테스트 및 디버깅 (2시간)

#### 테스트 시나리오

**Test 1: 단일 해시태그 수동 실행**
1. Set 노드에서 해시태그를 1개만 남기기 (`["buldak"]`)
2. Execute Workflow 클릭
3. 각 노드 실행 결과 확인:
   - HTTP Request (Apify Run): `defaultDatasetId` 확인
   - Wait: 2분 대기
   - HTTP Request (결과): 영상 데이터 배열 확인
   - Function: trend_score 값 확인
   - OpenAI: 카테고리 결과 확인
   - Airtable: 레코드 생성 확인

**Test 2: Airtable 데이터 검증**
1. Airtable Base 접속
2. `tiktok_trends` 테이블 확인
3. 모든 필드 값이 올바르게 입력되었는지 확인

**Test 3: 전체 해시태그 실행**
1. Set 노드에서 5개 해시태그 모두 활성화
2. Execute Workflow
3. 5개 레코드 생성 확인

#### 예상 오류 및 해결

| 오류 | 원인 | 해결 방법 |
|------|------|-----------|
| Apify timeout | Wait 시간 부족 | Wait를 3분으로 증가 |
| OpenAI rate limit | 너무 빠른 호출 | Split In Batches에 Delay 추가 |
| Airtable 필드 타입 불일치 | 숫자를 문자열로 전송 | Function에서 타입 변환 |
| `defaultDatasetId` undefined | Apify Run 실패 | HTTP Request 응답 확인, 토큰 재확인 |

### 1.6 워크플로우 Export 및 문서화 (30분)

#### 작업 내용
1. n8n에서 워크플로우 Export
   - Workflow → Download (JSON)
   - 파일명: `agent1_tiktok_trend_collector.json`
   - 저장 경로: `workflows/` 폴더 생성 후 저장

2. 구현 완료 보고서 작성
   - 파일: `step/Agent1_구현_완료.md`
   - 내용:
     - 실행 결과 (성공/실패)
     - 발생한 문제 및 해결 방법
     - Airtable 데이터 스크린샷
     - 소요 시간

---

## 🎯 Task 2: Agent 2 - RSS News Collector

### 2.1 RSS 피드 소스 테스트 (1시간)

#### 작업 내용
1. RSS URL 5개 확인 및 테스트

   **Source 1: TechCrunch**
   - URL: `https://techcrunch.com/tag/creator-economy/feed/`
   - 브라우저에서 XML 확인

   **Source 2: Medium**
   - URL: `https://medium.com/feed/tag/creator-economy`

   **Source 3: Google News**
   - URL: `https://news.google.com/rss/search?q=creator+economy+tiktok&hl=en-US&gl=US&ceid=US:en`

   **Source 4: The Verge**
   - URL: `https://www.theverge.com/rss/index.xml`

   **Source 5: Social Media Today**
   - URL: `https://www.socialmediatoday.com/rss`

2. n8n RSS Feed Read 노드로 각 소스 개별 테스트
   - 최근 24시간 기사가 있는지 확인
   - 필드 구조 파악: `title`, `link`, `pubDate`, `description`

### 2.2 n8n 워크플로우 구현 (4-5시간)

#### 노드 구조

**Step 1: 새 워크플로우 생성**
- Name: `Agent 2 - RSS News Collector`

**Step 2: 노드 추가**

1. **Schedule Trigger**
   - Cron: `0 10 * * *` (매일 10:00 KST)

2-6. **RSS Feed Read 노드 × 5개 (병렬)**
   - Node 2: TechCrunch RSS
     - URL: `https://techcrunch.com/tag/creator-economy/feed/`
   - Node 3: Medium RSS
   - Node 4: Google News RSS
   - Node 5: The Verge RSS
   - Node 6: Social Media Today RSS

7. **Merge 노드**
   - Mode: Combine
   - Combine By: Index
   - 5개 RSS 소스 모두 연결

8. **Remove Duplicates 노드**
   - Add Node → Remove Duplicates
   - Compare: `link`

9. **Limit 노드**
   - Add Node → Limit
   - Max Items: 10 (너무 많으면 OpenAI 비용 증가)

10. **Function 노드 (텍스트 정제)**
    - JavaScript:
      ```javascript
      const items = $input.all();

      return items.map(item => {
        const description = item.json.description || item.json.content || '';
        // HTML 태그 제거
        const cleanText = description.replace(/<[^>]*>/g, '');
        // 3000자 제한 (토큰 절약)
        const truncated = cleanText.substring(0, 3000);

        return {
          json: {
            title: item.json.title,
            url: item.json.link,
            content: truncated,
            published_at: new Date(item.json.pubDate).toISOString().split('T')[0],
            source: new URL(item.json.link).hostname
          }
        };
      });
      ```

11. **OpenAI 노드 (요약)**
    - Model: gpt-4o-mini
    - Message:
      ```
      Summarize this article in Korean (200 characters max).
      Focus on actionable insights for marketing professionals.

      Title: {{ $json.title }}
      Content: {{ $json.content }}

      Format:
      - One sentence summary
      - 2-3 key points
      ```
    - Temperature: 0.5

12. **Set 노드 (sentiment 및 topic 분류)**
    - Function으로 간단한 키워드 기반 분류
      ```javascript
      const summary = $json.message.content;

      // Sentiment 분류
      let sentiment = 'Neutral';
      if (summary.match(/증가|성장|성공|긍정|기회/)) sentiment = 'Positive';
      if (summary.match(/감소|하락|문제|부정|위기/)) sentiment = 'Negative';

      // Topic 분류
      let topic = 'Other';
      if (summary.includes('틱톡') || summary.includes('TikTok')) topic = 'TikTok';
      if (summary.includes('마케팅') || summary.includes('광고')) topic = 'Marketing';
      if (summary.includes('크리에이터') || summary.includes('인플루언서')) topic = 'Creator';

      return {
        json: {
          ...($input.first().json),
          summary: summary,
          sentiment: sentiment,
          topic: topic
        }
      };
      ```

13. **Airtable 노드 (Create)**
    - Base: `.env` 파일의 `AIRTABLE_BASE_ID` 값 (또는 직접 Base 선택)
    - Table: `research_news`
    - Fields:
      - title: `{{ $json.title }}`
      - url: `{{ $json.url }}`
      - summary: `{{ $json.summary }}`
      - sentiment: `{{ $json.sentiment }}`
      - topic: `{{ $json.topic }}`
      - published_at: `{{ $json.published_at }}`
      - source: `{{ $json.source }}`

### 2.3 테스트 및 디버깅 (1-2시간)

#### 테스트 시나리오

**Test 1: RSS 수집**
- 5개 소스 모두 데이터 수집 확인
- Merge 노드에서 통합 확인

**Test 2: 중복 제거**
- 같은 기사가 여러 소스에서 나올 경우 제거 확인

**Test 3: OpenAI 요약**
- 요약이 200자 이내인지 확인
- 한국어로 정확히 번역되었는지 확인

**Test 4: Airtable 저장**
- `research_news` 테이블에 레코드 생성 확인
- 모든 필드 값 정상 확인

### 2.4 워크플로우 Export 및 문서화 (30분)

#### 작업 내용
1. 워크플로우 Export
   - 파일: `workflows/agent2_rss_news_collector.json`

2. 구현 완료 보고서
   - 파일: `step/Agent2_구현_완료.md`

---

## 🎯 Task 3: Agent 3 - CLI Q&A Interface

### 3.1 Python 프로젝트 구조 설정 (1시간)

#### 폴더 구조
```
src/
├── agent3/
│   ├── __init__.py
│   ├── cli.py              # 메인 CLI 인터페이스
│   ├── query_engine.py     # 질문 처리 엔진
│   └── prompts.py          # OpenAI 프롬프트
├── data_connectors/
│   ├── __init__.py
│   └── airtable_client.py  # Airtable 연동
└── common/
    ├── __init__.py
    └── utils.py            # 유틸리티 함수
```

### 3.2 Airtable 클라이언트 구현 (2시간)

#### 파일: `src/data_connectors/airtable_client.py`

```python
from pyairtable import Api
from datetime import datetime, timedelta
import os
from typing import List, Dict, Optional

class AirtableClient:
    def __init__(self):
        self.api = Api(os.getenv('AIRTABLE_PAT'))
        self.base_id = os.getenv('AIRTABLE_BASE_ID')
        self.trends_table = self.api.table(self.base_id, 'tiktok_trends')
        self.news_table = self.api.table(self.base_id, 'research_news')

    def get_trends(self, days: int = 7, limit: int = 10) -> List[Dict]:
        """최근 N일간 트렌드 데이터 조회"""
        date_threshold = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')

        records = self.trends_table.all(
            formula=f"IS_AFTER({{collected_at}}, '{date_threshold}')",
            sort=[("trend_score", "desc")],
            max_records=limit
        )

        return [r['fields'] for r in records]

    def get_news(self, days: int = 7, limit: int = 10) -> List[Dict]:
        """최근 N일간 뉴스 데이터 조회"""
        date_threshold = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')

        records = self.news_table.all(
            formula=f"IS_AFTER({{published_at}}, '{date_threshold}')",
            sort=[("published_at", "desc")],
            max_records=limit
        )

        return [r['fields'] for r in records]

    def search_by_keyword(self, keyword: str, table: str = 'both') -> Dict:
        """키워드로 데이터 검색"""
        results = {'trends': [], 'news': []}

        if table in ['trends', 'both']:
            trends = self.trends_table.all(
                formula=f"SEARCH(LOWER('{keyword}'), LOWER({{keyword}}))",
                max_records=5
            )
            results['trends'] = [r['fields'] for r in trends]

        if table in ['news', 'both']:
            news = self.news_table.all(
                formula=f"OR(SEARCH(LOWER('{keyword}'), LOWER({{title}})), SEARCH(LOWER('{keyword}'), LOWER({{summary}})))",
                max_records=5
            )
            results['news'] = [r['fields'] for r in news]

        return results
```

### 3.3 Query Engine 구현 (3-4시간)

#### 파일: `src/agent3/query_engine.py`

```python
from openai import OpenAI
from src.data_connectors.airtable_client import AirtableClient
import os
from typing import Dict

class QueryEngine:
    def __init__(self):
        self.openai_client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.airtable = AirtableClient()

    def classify_question(self, question: str) -> Dict:
        """질문을 분류하여 적절한 데이터 소스 결정"""
        prompt = f"""Classify this question into a category and extract key information.

Question: {question}

Categories:
- trend: Questions about TikTok hashtags, trends, viral content
- research: Questions about creator economy news, articles, business insights
- mixed: Questions requiring both trend and research data

Also extract:
- days: Number of days to look back (7, 30, or all)
- keywords: Important keywords for searching

Respond in JSON format:
{{
  "category": "trend|research|mixed",
  "days": 7,
  "keywords": ["keyword1", "keyword2"]
}}
"""

        response = self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            response_format={"type": "json_object"}
        )

        import json
        return json.loads(response.choices[0].message.content)

    def prepare_context(self, classification: Dict) -> str:
        """Airtable 데이터를 조회하여 컨텍스트 준비"""
        category = classification['category']
        days = classification.get('days', 7)
        keywords = classification.get('keywords', [])

        context = ""

        # 키워드 검색 우선
        if keywords:
            search_results = self.airtable.search_by_keyword(keywords[0])

            if search_results['trends']:
                context += "## TikTok Trends\n"
                for trend in search_results['trends'][:5]:
                    context += f"- {trend['keyword']}: Score {trend['trend_score']}, {trend['video_count']} videos\n"

            if search_results['news']:
                context += "\n## Research News\n"
                for news in search_results['news'][:5]:
                    context += f"- {news['title']}: {news['summary']}\n"

        # 카테고리별 기본 데이터
        else:
            if category in ['trend', 'mixed']:
                trends = self.airtable.get_trends(days=days)
                context += "## Recent TikTok Trends\n"
                for trend in trends:
                    context += f"- {trend['keyword']}: Score {trend['trend_score']}, {trend.get('video_count', 0)} videos, Category: {trend.get('category', 'N/A')}\n"

            if category in ['research', 'mixed']:
                news = self.airtable.get_news(days=days)
                context += "\n## Recent News\n"
                for article in news:
                    context += f"- {article['title']}: {article['summary']} (Source: {article.get('source', 'N/A')})\n"

        return context

    def generate_answer(self, question: str, context: str) -> str:
        """OpenAI로 RAG 답변 생성"""
        prompt = f"""You are a TikTok and creator economy research assistant.

Answer the question based ONLY on the provided data. Do not hallucinate.
If the data doesn't contain the answer, say "현재 데이터에는 해당 정보가 없습니다."

Respond in Korean with:
1. Direct answer (1-2 sentences)
2. Key points (2-3 bullet points)
3. Actionable insight (1 sentence)

Question: {question}

Data:
{context}
"""

        response = self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
            max_tokens=500
        )

        return response.choices[0].message.content

    def process_question(self, question: str) -> str:
        """전체 질문 처리 파이프라인"""
        # 1. 질문 분류
        classification = self.classify_question(question)

        # 2. 컨텍스트 준비
        context = self.prepare_context(classification)

        if not context.strip():
            return "현재 데이터에는 해당 정보가 없습니다. 더 많은 데이터가 수집되면 답변할 수 있습니다."

        # 3. 답변 생성
        answer = self.generate_answer(question, context)

        # 4. 출처 추가
        answer += f"\n\n📎 출처: Airtable (최근 {classification.get('days', 7)}일)"

        return answer
```

### 3.4 CLI 인터페이스 구현 (2-3시간)

#### 파일: `src/agent3/cli.py`

```python
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel
from src.agent3.query_engine import QueryEngine
from dotenv import load_dotenv
import time

load_dotenv()

console = Console()
engine = QueryEngine()

def print_welcome():
    """시작 화면 출력"""
    welcome_text = """
# TikTok Research Agent

질문을 입력하세요. 종료하려면 'exit'를 입력하세요.

## 샘플 질문:
- 최근 1주일 가장 핫한 해시태그는?
- 크리에이터 이코노미 최신 트렌드는?
- #buldak 트렌드 분석해줘
    """
    console.print(Panel(Markdown(welcome_text), title="Welcome", border_style="cyan"))

def main():
    print_welcome()

    while True:
        console.print("\n")
        question = console.input("[bold cyan]질문 > [/bold cyan]")

        if question.lower() in ['exit', 'quit', '종료']:
            console.print("[yellow]종료합니다. 안녕히 가세요![/yellow]")
            break

        if not question.strip():
            continue

        # 로딩 애니메이션
        with console.status("[cyan]검색 중...[/cyan]", spinner="dots"):
            start_time = time.time()
            answer = engine.process_question(question)
            elapsed = time.time() - start_time

        # 답변 출력
        console.print("\n")
        console.print(Panel(Markdown(answer), title="답변", border_style="green"))
        console.print(f"[dim]실행 시간: {elapsed:.1f}초[/dim]")

if __name__ == "__main__":
    main()
```

### 3.5 테스트 (2시간)

#### 테스트 시나리오

**Test 1: 기본 질문**
```bash
python src/agent3/cli.py

질문 > 최근 1주일 가장 핫한 해시태그는?
# 예상: tiktok_trends 테이블 조회 → Top 3 반환
```

**Test 2: 키워드 검색**
```bash
질문 > #buldak 트렌드 분석해줘
# 예상: keyword 필드에서 "buldak" 검색 → 상세 정보
```

**Test 3: 뉴스 질문**
```bash
질문 > 크리에이터 이코노미 최신 트렌드는?
# 예상: research_news 테이블 조회 → 최근 뉴스 요약
```

**Test 4: 관련 없는 질문**
```bash
질문 > 내일 날씨는?
# 예상: "현재 데이터에는 해당 정보가 없습니다."
```

**Test 5: 복합 질문**
```bash
질문 > #buldak 트렌드와 관련된 뉴스는?
# 예상: 트렌드 + 뉴스 혼합 답변
```

### 3.6 문서화 (1시간)

#### 파일: `step/Agent3_구현_완료.md`

```markdown
# Agent 3 구현 완료 보고서

## 구현 내용
- Airtable 클라이언트 (조회, 검색)
- Query Engine (질문 분류, 컨텍스트 준비, RAG 답변)
- CLI 인터페이스 (Rich 라이브러리)

## 테스트 결과
- 5개 샘플 질문 테스트
- 정확도: 80% 이상
- 평균 응답 시간: 8-12초

## 발생한 문제
- (문제 발생 시 기록)

## 스크린샷
- CLI 실행 화면
- 질문-답변 예시
```

---

## 📊 완료 체크리스트

### Agent 1 (TikTok Trend Collector)
- [ ] n8n Credentials 등록 (Airtable, OpenAI, Apify)
- [ ] Apify API 구조 파악 및 테스트
- [ ] n8n 워크플로우 10개 노드 구현
- [ ] 단일 해시태그 테스트 성공
- [ ] 5개 해시태그 전체 실행 성공
- [ ] Airtable에 데이터 5개 이상 저장 확인
- [ ] 워크플로우 JSON Export
- [ ] `step/Agent1_구현_완료.md` 작성

### Agent 2 (RSS News Collector)
- [ ] RSS 피드 5개 URL 테스트
- [ ] n8n 워크플로우 13개 노드 구현
- [ ] RSS 수집 및 중복 제거 확인
- [ ] OpenAI 요약 품질 확인
- [ ] Airtable에 뉴스 5개 이상 저장 확인
- [ ] 워크플로우 JSON Export
- [ ] `step/Agent2_구현_완료.md` 작성

### Agent 3 (CLI Q&A Interface)
- [ ] Python 폴더 구조 생성
- [ ] `airtable_client.py` 구현
- [ ] `query_engine.py` 구현
- [ ] `cli.py` 구현
- [ ] 5개 샘플 질문 테스트 (정확도 80%+)
- [ ] 평균 응답 시간 10초 이내 확인
- [ ] `step/Agent3_구현_완료.md` 작성

---

## 🎯 다음 단계

모든 에이전트 구현 완료 후:
1. README.md 작성 (프로젝트 개요, 설치 가이드)
2. 스크린샷 촬영 (최소 5장)
3. 데모 영상 촬영 (선택)
4. GitHub 리포지토리 정리 및 공개

---

**작성일**: 2025-12-19
**버전**: 1.0
**문서 목적**: 실제 구현 시 이 문서만 보고 순차적으로 작업 진행
